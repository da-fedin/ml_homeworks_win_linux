{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ev8aEQqqmf5"
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKW2OdUYqrd1",
    "outputId": "814b15ef-861b-4fde-cd09-461ae90ed733"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in80XwH8yItW"
   },
   "source": [
    "# Getting data\n",
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCHC3LnZyLyW"
   },
   "outputs": [],
   "source": [
    "# Set file path\n",
    "path_to_dataset = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "# Load data from a text file, with missing values handled as specified.\n",
    "data_set = np.genfromtxt(\n",
    "    path_to_dataset,\n",
    "    dtype='float',\n",
    "    delimiter=',',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T14:46:47.769292700Z",
     "start_time": "2024-02-18T14:46:47.756205600Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Size: {data_set.size}; shape: {data_set.shape}; dtype: {data_set.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmnK6sJRyjNm"
   },
   "source": [
    "# Tasks\n",
    "Find target column in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target column as one which doesn't have numerical values\n",
    "target_columns = np.any(\n",
    "    np.isnan(data_set),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "# Get index for target column\n",
    "target_index = np.where(target_columns == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dY4QIP06WH0"
   },
   "source": [
    "Get feature set from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXbEv5d96XbW"
   },
   "outputs": [],
   "source": [
    "# Drop target column to get feature dataset\n",
    "if target_index:\n",
    "  feature_set = np.delete(\n",
    "      arr=data_set,\n",
    "      obj=target_index,\n",
    "      axis=1,\n",
    "  )\n",
    "else:\n",
    "  feature_set = data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQVj-A9W7YsB"
   },
   "source": [
    "Check if feature set has type np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCbY7gKY7h8F",
    "outputId": "da8958bd-a1c3-4dfb-ec6a-98eca765eb41"
   },
   "outputs": [],
   "source": [
    "if type(feature_set) != np.ndarray:\n",
    "  raise Exception(\"Error: feature set hasn't type np.ndarray\")\n",
    "else:\n",
    "  print(\"Featureset has type np.ndarray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL9hEEKD-Oo5"
   },
   "source": [
    "Get mean value for the 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Y5cTkyH-Qkd",
    "outputId": "51306760-7f12-49d1-d018-1fb80f0979e7"
   },
   "outputs": [],
   "source": [
    "mean_for_first_column = np.mean(\n",
    "    a=feature_set[:, 0],\n",
    ")\n",
    "\n",
    "f\"Mean value for the 1st column is {mean_for_first_column:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Pqr9dxL_eDa"
   },
   "source": [
    "Get median value for the 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7Lt-A4G_fct",
    "outputId": "edfece5f-63bc-4afc-d68c-6296f3413b26"
   },
   "outputs": [],
   "source": [
    "median_for_first_column = np.median(\n",
    "    a=feature_set[:, 0],\n",
    ")\n",
    "\n",
    "f\"Median value for the 1st column is {median_for_first_column:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_W3m584A16J"
   },
   "source": [
    "Get standard deviation for the 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Qw2bWjA5yZ",
    "outputId": "4d9a4297-6085-48d3-f0c2-8315838d1a8a"
   },
   "outputs": [],
   "source": [
    "stdev_for_first_column = np.std(\n",
    "    a=feature_set[:, 0],\n",
    ")\n",
    "\n",
    "f\"Standard deviation for the 1st column is {stdev_for_first_column:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df5EXIsxB33i"
   },
   "source": [
    "Substitute 20 NaNs to random positions in set with no repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2d7ce-QCm6e",
    "outputId": "b1a7f29e-becb-4456-8db7-116cf566b21a"
   },
   "outputs": [],
   "source": [
    "nan_amount = 20\n",
    "random_positions = set()\n",
    "updated_feature_set = np.copy(feature_set)\n",
    "\n",
    "rows, cols = feature_set.shape\n",
    "\n",
    "# Get random positions\n",
    "while True:\n",
    "  random_row = np.random.choice(rows)\n",
    "  random_col = np.random.choice(cols)\n",
    "\n",
    "  random_positions.add((random_row, random_col))\n",
    "  if len(random_positions) == 20:\n",
    "    break\n",
    "\n",
    "# Update items in dataset with nan in defined random positions\n",
    "for item in random_positions:\n",
    "    updated_feature_set[item[0], item[1]] = np.nan\n",
    "\n",
    "# Get number of nans in updated feature_set\n",
    "number_of_nans = len(\n",
    "    np.where(np.isnan(updated_feature_set))[0]\n",
    ")\n",
    "print(f\"{number_of_nans} items in feature_set substituted by NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MB-R-rlRCtm"
   },
   "source": [
    "Get positions of NaNs in 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dl4A2ytYRGrb",
    "outputId": "ae139b22-cb99-4ed3-cda6-e68acb4f6542"
   },
   "outputs": [],
   "source": [
    "nan_positions = np.where(np.isnan(updated_feature_set[:, 0]))\n",
    "\n",
    "print(\"Positions of nan in 1st column are:\\n\")\n",
    "\n",
    "for item in nan_positions[0]:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep3VXKUQWWvc"
   },
   "source": [
    "Filter updated featureset by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLA5nKbnWekU",
    "outputId": "0083b4a4-3533-4cca-e2e7-b2ba697bdb21"
   },
   "outputs": [],
   "source": [
    "# Set condition to filter dataset\n",
    "condition = (updated_feature_set[:, 2] > 1.5) & (updated_feature_set[:, 0] < 5.0)\n",
    "\n",
    "# Filter dataset\n",
    "filtered_feature_set = updated_feature_set[condition]\n",
    "\n",
    "filtered_feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRC4zpU4ZySK"
   },
   "source": [
    "Change all NaNs to 0 in updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute nans by 0\n",
    "np.nan_to_num(\n",
    "    x=updated_feature_set,\n",
    "    nan=0,\n",
    "    copy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Count unique items and return them with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTZxrp2nZ4l8",
    "outputId": "4c113f57-173f-4913-8a42-f7b1664dbc62"
   },
   "outputs": [],
   "source": [
    "# Get unique items and their counts\n",
    "unique_items = np.unique(\n",
    "    ar=updated_feature_set,\n",
    "    return_counts='True',\n",
    ")\n",
    "\n",
    "# Count unique items\n",
    "number_of_unique = len(unique_items[0])\n",
    "\n",
    "print(f\"Number of unique items is {number_of_unique}\\n\")\n",
    "\n",
    "# Return unique items with their count\n",
    "for item, count in zip(unique_items[0], unique_items[1]):\n",
    "  print(f\"Item {item} appears {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnZGDPIufiqB"
   },
   "source": [
    "Split array to 2 parts vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsXl9tUaftqy"
   },
   "outputs": [],
   "source": [
    "num_splits = 2\n",
    "\n",
    "# Split the array vertically along axis 0\n",
    "first_subarray, second_subarray = np.array_split(\n",
    "    ary=updated_feature_set,\n",
    "    indices_or_sections=num_splits,\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(f\"First subarray is of shape: {first_subarray.shape}\\nSecond subarray is of shape: {second_subarray.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm_1o4hCh6iw"
   },
   "source": [
    "Sort sub-arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6RHxprQh-aX"
   },
   "outputs": [],
   "source": [
    "# Set axis to sort along with\n",
    "axis_to_sort = 0\n",
    "\n",
    "# Sort first sub-array in ascending order\n",
    "sorted_first_part = np.sort(\n",
    "    a=first_subarray,\n",
    "    axis=axis_to_sort,\n",
    ")\n",
    "\n",
    "# Sort first sub-array in descending order\n",
    "sorted_second_part = np.sort(\n",
    "    a=second_subarray,\n",
    "    axis=axis_to_sort\n",
    ")[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-_KqGABlSI7"
   },
   "source": [
    "Concatenate sub-arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxAyoVE2l2yw",
    "outputId": "028f04af-1a7e-489d-b80f-ea8ccfa27a03"
   },
   "outputs": [],
   "source": [
    "concatenated_array = np.concatenate(\n",
    "    (sorted_first_part, sorted_second_part),\n",
    "    axis=axis_to_sort,\n",
    ")\n",
    "\n",
    "concatenated_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE5S5eJgmrRI"
   },
   "source": [
    "Get most common item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FKe5x1Bm5nq",
    "outputId": "0a179b36-b18c-44e8-889a-f9ce4073cb38"
   },
   "outputs": [],
   "source": [
    "# Get unique items\n",
    "unique_elements, counts = np.unique(\n",
    "    ar=concatenated_array,\n",
    "    return_counts=True,\n",
    ")\n",
    "\n",
    "# Get index of element with maximum count\n",
    "max_count_index = np.argmax(counts)\n",
    "\n",
    "# Get the element with the maximum count\n",
    "item_with_max_count = unique_elements[max_count_index]\n",
    "\n",
    "item_with_max_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOjplFk4nanz"
   },
   "source": [
    "Set function to multiply items of defined column conditionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n86jpmz5oPyK"
   },
   "outputs": [],
   "source": [
    "# Get array and process elements in defined column\n",
    "def process_array(processed_array, processed_column):\n",
    "    mean_value = np.mean(a=processed_array[:, processed_column])\n",
    "    \n",
    "    print(f\" Mean value: {mean_value:.2f}\")\n",
    "\n",
    "    processed_array[:, processed_column] = np.where(\n",
    "        processed_array[:, processed_column] < mean_value,\n",
    "        processed_array[:, processed_column] / 2,\n",
    "        processed_array[:, processed_column] / 4\n",
    "    )\n",
    "\n",
    "    return processed_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewerFX_tQifj"
   },
   "source": [
    "Process 3rd column of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWKum70zQnA3",
    "outputId": "657fdd2e-30cc-4173-c35d-427a165c3439"
   },
   "outputs": [],
   "source": [
    "processed_array = process_array(concatenated_array, 2)\n",
    "\n",
    "processed_array"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
