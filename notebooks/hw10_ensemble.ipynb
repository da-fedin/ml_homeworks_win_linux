{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.125863200Z",
     "start_time": "2024-02-14T12:13:36.687613800Z"
    }
   },
   "outputs": [],
   "source": [
    "# To mute annoying warnings in notebook\n",
    "import warnings\n",
    "\n",
    "# For runtime estimation\n",
    "import time\n",
    "\n",
    "# For Data science\n",
    "import pandas as pd\n",
    "from sklearn import (\n",
    "    model_selection,\n",
    "    ensemble,\n",
    "    tree,\n",
    "    linear_model,\n",
    "    svm,\n",
    ")\n",
    "\n",
    "# For visualization\n",
    "# general\n",
    "import seaborn as sns\n",
    "\n",
    "# Math plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For timing\n",
    "# For modules\n",
    "from sources import (\n",
    "    check_is_na,\n",
    "    get_dataframe_scaled,\n",
    ")\n",
    "\n",
    "# Dealing with classification with imbalanced classes\n",
    "from imblearn import (\n",
    "    over_sampling,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.138739300Z",
     "start_time": "2024-02-14T12:13:37.127860600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset from file\n",
    "data = pd.read_csv(\n",
    "    \"../data/data.csv\",\n",
    "    delimiter=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The dataset contains second target - Time of verification. I don't see ane sense to use the time as target for classification. I drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.184255600Z",
     "start_time": "2024-02-14T12:13:37.140737600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop second target\n",
    "# data.drop(columns=['verification.time'], inplace=True)\n",
    "\n",
    "# Rename columns to get short labels\n",
    "data.columns = [\"b1\", \"b2\", \"b3\", \"b4\", \"price\", \"product\", \"winner\", \"result\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.187253700Z",
     "start_time": "2024-02-14T12:13:37.150958500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get info about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.251885400Z",
     "start_time": "2024-02-14T12:13:37.170169700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get stat for dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:37.254883200Z",
     "start_time": "2024-02-14T12:13:37.207310900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "check_is_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Visualize correlation of data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:39.963743700Z",
     "start_time": "2024-02-14T12:13:37.216842900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show correlation between targets\n",
    "sns.pairplot(data=data[[\"result\", \"price\"]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Yes, pair plot is not a good way to get correlation between categorical features, but for time and result it partially shows that there is some relation. Let's discover it with more appropriate tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make categorical feature from continuous feature 'time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:39.977536400Z",
     "start_time": "2024-02-14T12:13:39.964742900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get mean time\n",
    "mean_time = data.time.mean()\n",
    "\n",
    "# Make feature as categorical\n",
    "data[\"duration\"] = data.time.apply(lambda x: \"big\" if x > mean_time else \"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Count how many occurrences there are of each combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:40.118829900Z",
     "start_time": "2024-02-14T12:13:39.974538900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "contingency_table = pd.crosstab(data.result, data.duration)\n",
    "\n",
    "# Show occurrences table\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:40.342416Z",
     "start_time": "2024-02-14T12:13:40.002398500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show occurrences diagram\n",
    "sns.heatmap(contingency_table);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It looks like there is a correlation. It worth it to take it into account before classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature engineering\n",
    "Make a new feature by combining correlated targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:40.379461300Z",
     "start_time": "2024-02-14T12:13:40.328675500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine targets\n",
    "data[\"combined_target\"] = data.duration + \"_\" + data.result.astype(str)\n",
    "\n",
    "# Get stat\n",
    "data.combined_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.028122100Z",
     "start_time": "2024-02-14T12:13:40.347412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show occurrences\n",
    "sns.catplot(data=data, x=\"combined_target\", kind=\"count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dataset looks imbalanced by target. Let's balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.030121Z",
     "start_time": "2024-02-14T12:13:41.015366800Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"result\", \"time\", \"duration\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.047395100Z",
     "start_time": "2024-02-14T12:13:41.022127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale dataset\n",
    "scaled_df = get_dataframe_scaled(dataset=data, omit_feature_names=[\"combined_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.133119300Z",
     "start_time": "2024-02-14T12:13:41.038520300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make feature subset\n",
    "X = data.drop(\"combined_target\", axis=1)\n",
    "\n",
    "# Make target subset\n",
    "y = data.combined_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.137117700Z",
     "start_time": "2024-02-14T12:13:41.048391900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize random over sampler\n",
    "random_over_sampler = over_sampling.RandomOverSampler(\n",
    "    random_state=0,\n",
    "    sampling_strategy=\"not majority\",\n",
    ")\n",
    "\n",
    "# Resample data\n",
    "X_resampled, y_resampled = random_over_sampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.138117100Z",
     "start_time": "2024-02-14T12:13:41.066675100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get split subsets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.622993100Z",
     "start_time": "2024-02-14T12:13:41.077961600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show resampled target\n",
    "sns.catplot(\n",
    "    data=y_resampled.to_frame(),\n",
    "    x=\"combined_target\",\n",
    "    kind=\"count\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classification with default hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BaggingClassifier:\n",
    "\n",
    "fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.708255600Z",
     "start_time": "2024-02-14T12:13:41.625990100Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Get classifier with base estimator as a DecisionTreeClassifier and default number of estimators 10\n",
    "bagging_classifier = ensemble.BaggingClassifier(\n",
    "    random_state=0,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get score\n",
    "bagging_score = bagging_classifier.score(X_test, y_test)\n",
    "\n",
    "print(f\"Bagging_score score is {bagging_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:41.710254900Z",
     "start_time": "2024-02-14T12:13:41.688718500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_predicted_bagging = bagging_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:42.936011100Z",
     "start_time": "2024-02-14T12:13:41.703259900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make dataframe from test and predicted values\n",
    "data_to_compare = pd.DataFrame(\n",
    "    {\"values from test\": y_test, \"predicted values\": y_predicted_bagging}\n",
    ")\n",
    "\n",
    "# Visualize amount of predicted values\n",
    "sns.barplot(\n",
    "    x=\"value\",\n",
    "    y=\"index\",\n",
    "    hue=\"variable\",\n",
    "    data=pd.melt(data_to_compare.reset_index(), id_vars=\"index\"),\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of observations in test dataset and and predicted dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Histogram-Based Gradient Boosting:\n",
    "\n",
    "builds an additive model in a forward stage-wise fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:45.460961100Z",
     "start_time": "2024-02-14T12:13:42.914024600Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Get classifier\n",
    "boosting_classifier = ensemble.HistGradientBoostingClassifier(random_state=0).fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get score\n",
    "boosting_score = boosting_classifier.score(X_test, y_test)\n",
    "\n",
    "print(f\"Boosting score is {boosting_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:45.517620300Z",
     "start_time": "2024-02-14T12:13:45.462960500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_predicted_boosting = boosting_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:46.284756300Z",
     "start_time": "2024-02-14T12:13:45.505555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make dataframe from test and predicted values\n",
    "data_to_compare = pd.DataFrame(\n",
    "    {\"values from test\": y_test, \"predicted values\": y_predicted_boosting}\n",
    ")\n",
    "\n",
    "# Visualize amount of predicted values\n",
    "sns.barplot(\n",
    "    x=\"value\",\n",
    "    y=\"index\",\n",
    "    hue=\"variable\",\n",
    "    data=pd.melt(data_to_compare.reset_index(), id_vars=\"index\"),\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of observations in test dataset and and predicted dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Stacked generalization:\n",
    "\n",
    "The predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:46.549655300Z",
     "start_time": "2024-02-14T12:13:46.287756700Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Get estimator\n",
    "estimators = [\n",
    "    (\"rf\", ensemble.RandomForestClassifier(n_estimators=10, random_state=0)),\n",
    "]\n",
    "\n",
    "# Get classifier\n",
    "stacking_classifier = ensemble.StackingClassifier(estimators=estimators).fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get score\n",
    "stacking_score = stacking_classifier.score(X_test, y_test)\n",
    "\n",
    "print(f\"Stacking score is {stacking_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:46.562572600Z",
     "start_time": "2024-02-14T12:13:46.550654500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_predicted_stacking = stacking_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:13:47.313380700Z",
     "start_time": "2024-02-14T12:13:46.571645600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make dataframe from test and predicted values\n",
    "data_to_compare = pd.DataFrame(\n",
    "    {\"values from test\": y_test, \"predicted values\": y_predicted_stacking}\n",
    ")\n",
    "\n",
    "# Visualize amount of predicted values\n",
    "sns.barplot(\n",
    "    x=\"value\",\n",
    "    y=\"index\",\n",
    "    hue=\"variable\",\n",
    "    data=pd.melt(data_to_compare.reset_index(), id_vars=\"index\"),\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of observations in test dataset and and predicted dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classification with selection of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BaggingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:15:26.006941600Z",
     "start_time": "2024-02-14T12:13:47.317378600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get parameter grid\n",
    "parameter_grid = {\n",
    "    \"base_estimator\": [\n",
    "        tree.DecisionTreeClassifier(),\n",
    "        linear_model.LogisticRegression(),\n",
    "    ],\n",
    "    \"n_estimators\": [5, 10, 20],\n",
    "    \"max_samples\": [0.5, 0.7, 0.9],\n",
    "    \"max_features\": [0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "# Get grid search\n",
    "greed_search = model_selection.GridSearchCV(\n",
    "    estimator=bagging_classifier,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit grid search\n",
    "greed_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get grid search metrics\n",
    "best_parameters = greed_search.best_params_\n",
    "best_bagging_estimator = greed_search.best_estimator_\n",
    "accuracy = best_bagging_estimator.score(X_test, y_test)\n",
    "best_score = greed_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_parameters}\")\n",
    "print(f\"Best bagging estimator: {best_bagging_estimator}\")\n",
    "print(f\"Best score: {best_score:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using SVC returns warning! Something is wrong with bagging-SVC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:21:44.418632900Z",
     "start_time": "2024-02-14T12:15:26.002942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get parameter grid\n",
    "parameter_grid = {\n",
    "    \"early_stopping\": [True, False],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_iter\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "}\n",
    "\n",
    "# Get grid search\n",
    "greed_search = model_selection.GridSearchCV(\n",
    "    estimator=boosting_classifier,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit grid search\n",
    "greed_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get grid search metrics\n",
    "best_parameters = greed_search.best_params_\n",
    "best_bagging_estimator = greed_search.best_estimator_\n",
    "accuracy = best_bagging_estimator.score(X_test, y_test)\n",
    "best_score = greed_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_parameters}\")\n",
    "print(f\"Best boosting estimator: {best_bagging_estimator}\")\n",
    "print(f\"Best score: {best_score:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Stacked generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T12:32:54.006403500Z",
     "start_time": "2024-02-14T12:21:44.424630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get parameter grid\n",
    "parameter_grid = {\n",
    "    \"estimators\": [\n",
    "        [\n",
    "            (\"lr\", linear_model.LogisticRegression()),\n",
    "            (\"rf\", ensemble.RandomForestClassifier()),\n",
    "        ],\n",
    "        [(\"lr\", linear_model.LogisticRegression()), (\"svm\", svm.SVC(probability=True))],\n",
    "        [(\"rf\", ensemble.RandomForestClassifier()), (\"svm\", svm.SVC(probability=True))],\n",
    "    ],\n",
    "    \"final_estimator\": [\n",
    "        linear_model.LogisticRegression(),\n",
    "        ensemble.RandomForestClassifier(),\n",
    "    ],\n",
    "    \"cv\": [3, 5],\n",
    "    \"stack_method\": [\"auto\", \"predict_proba\"],\n",
    "}\n",
    "\n",
    "# Get grid search\n",
    "greed_search = model_selection.GridSearchCV(\n",
    "    estimator=stacking_classifier,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit grid search\n",
    "greed_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Get grid search metrics\n",
    "best_parameters = greed_search.best_params_\n",
    "best_bagging_estimator = greed_search.best_estimator_\n",
    "accuracy = best_bagging_estimator.score(X_test, y_test)\n",
    "best_score = greed_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_parameters}\")\n",
    "print(f\"Best stacking estimator: {best_bagging_estimator}\")\n",
    "print(f\"Best score: {best_score:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summary\n",
    "1. Bagging, boosting and stacking methods used for classification.\n",
    "2. The quality of classification is good enough for all methods with default hyperparameters.\n",
    "3. Bagging method is faster and boosting method is slower with default hyperparameters.\n",
    "4. The best combination of the chosen hyperparameters for each method found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
