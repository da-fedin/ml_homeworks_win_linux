{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc6a390695eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:38:15.891335400Z",
     "start_time": "2024-02-22T08:38:15.879831100Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "\n",
    "from transformers import TFMarianMTModel, MarianTokenizer\n",
    "import sacrebleu\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2d80571cbbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:38:21.923831200Z",
     "start_time": "2024-02-22T08:38:15.895329400Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6e96bbb3483a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:38:24.770229400Z",
     "start_time": "2024-02-22T08:38:21.923831200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define input text\n",
    "input_text = \"Hello, how have You been?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer([input_text], return_tensors=\"tf\", padding=True)\n",
    "\n",
    "# Translate input text\n",
    "translated_tokens = model.generate(input_ids[\"input_ids\"])\n",
    "\n",
    "# Decode translated tokens\n",
    "translated_text = tokenizer.decode(\n",
    "    translated_tokens.numpy()[0], skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(f\"Input Text: {input_text}.\")\n",
    "print(f\"Translated Text: {translated_text}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941397cb908869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:38:24.780707600Z",
     "start_time": "2024-02-22T08:38:24.770229400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "references = [input_text]\n",
    "hypotheses = [translated_text]\n",
    "\n",
    "bleu_score = sacrebleu.corpus_bleu(hypotheses, [references]).score\n",
    "\n",
    "chrf_score = sacrebleu.corpus_chrf(hypotheses, [references]).score\n",
    "\n",
    "ter_score = sacrebleu.corpus_ter(hypotheses, [references]).score\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.2f}.\")\n",
    "print(f\"chrF Score: {chrf_score:.2f}.\")\n",
    "print(f\"TER Score: {ter_score:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb8e9204e698e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:38:24.827387700Z",
     "start_time": "2024-02-22T08:38:24.781707600Z"
    }
   },
   "outputs": [],
   "source": [
    "config = model.config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c9973e7e7a85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T08:46:47.619008900Z",
     "start_time": "2024-02-22T08:46:31.158765500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model name\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Define input text and reference translation\n",
    "input_text = \"Hello, how have you been?\"\n",
    "reference_translation = \"Привіт, як справи?\"\n",
    "\n",
    "# Define candidate configurations to try\n",
    "configurations = [\n",
    "    {\"max_length\": 128, \"num_beams\": 4},\n",
    "    {\"max_length\": 256, \"num_beams\": 8},\n",
    "    {\"max_length\": 512, \"num_beams\": 16},\n",
    "]\n",
    "\n",
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(config)\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        input_ids, max_length=config[\"max_length\"], num_beams=config[\"num_beams\"]\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        translated_tokens.numpy()[0], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [[reference_translation]]).score\n",
    "\n",
    "    # Update best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "        best_configuration = config\n",
    "\n",
    "# Print the best configuration and BLEU score\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(\"Best BLEU Score:\", best_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22122e7c62f0e17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:12:20.013992900Z",
     "start_time": "2024-02-22T09:03:46.125800500Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define candidate parameter values\n",
    "max_lengths = [128, 256, 512]\n",
    "num_beams_list = [4, 8, 16]\n",
    "num_hidden_layers_list = [2, 4, 6]\n",
    "max_position_embeddings_list = [\n",
    "    128,\n",
    "    256,\n",
    "    512,\n",
    "]  # Define different values for max_position_embeddings\n",
    "use_cache_list = [True, False]  # Define different values for use_cache\n",
    "\n",
    "# Generate all possible combinations of parameter values\n",
    "configurations = list(\n",
    "    itertools.product(\n",
    "        max_lengths,\n",
    "        num_beams_list,\n",
    "        num_hidden_layers_list,\n",
    "        max_position_embeddings_list,\n",
    "        use_cache_list,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    max_length, num_beams, num_hidden_layers, max_pos_emb, cache = config\n",
    "\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(\n",
    "        {\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            \"max_position_embeddings\": max_pos_emb,\n",
    "            \"use_cache\": cache,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        input_ids, max_length=max_length, num_beams=num_beams\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        translated_tokens.numpy()[0], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [[reference_translation]]).score\n",
    "\n",
    "    # Update best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "        best_configuration = {\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            \"max_position_embeddings\": max_pos_emb,\n",
    "            \"use_cache\": cache,\n",
    "        }\n",
    "\n",
    "# Print the best configuration and BLEU score\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(\"Best BLEU Score:\", best_bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
