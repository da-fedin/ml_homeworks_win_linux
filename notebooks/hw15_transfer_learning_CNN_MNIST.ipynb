{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:26.480182Z",
     "start_time": "2024-02-11T21:55:26.287377100Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN, ProgbarLogger, TensorBoard, LearningRateScheduler\n",
    "\n",
    "# For runtime estimation\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Mute warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:26.510164700Z",
     "start_time": "2024-02-11T21:55:26.470187600Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Suppress specific warning message\n",
    "# warnings.filterwarnings(\n",
    "#     action='ignore',\n",
    "#     message='The name*',\n",
    "# )\n",
    "# \n",
    "# warnings.filterwarnings(\n",
    "#     action='ignore',\n",
    "#     message='tensorflow*',\n",
    "# )\n",
    "# \n",
    "# warnings.filterwarnings(\n",
    "#     action='ignore',\n",
    "#     message='WARNING*',\n",
    "# )\n",
    "# \n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# disable_interactive_logging();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:26.564186300Z",
     "start_time": "2024-02-11T21:55:26.515215700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:26.902240Z",
     "start_time": "2024-02-11T21:55:26.549194500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Show original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:29.378057200Z",
     "start_time": "2024-02-11T21:55:26.865263200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample 25 mnist digits from train dataset\n",
    "indexes = np.random.randint(0, train_images.shape[0], size=25)\n",
    "images = train_images[indexes]\n",
    "labels = train_labels[indexes]\n",
    "\n",
    "# Plot the 25 mnist digits\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "for i in range(len(indexes)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "plt.savefig(\"mnist-samples.png\")\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing\n",
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:42.485515600Z",
     "start_time": "2024-02-11T21:55:29.382054200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resize images to match the required input size of DenseNet (32x32)\n",
    "train_images_resized = np.array([resize(img, (32, 32)) for img in train_images])\n",
    "test_images_resized = np.array([resize(img, (32, 32)) for img in test_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:42.731158200Z",
     "start_time": "2024-02-11T21:55:42.491513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images_resized = train_images_resized.astype('float32') / 255\n",
    "test_images_resized = test_images_resized.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Replicate channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:44.038365900Z",
     "start_time": "2024-02-11T21:55:42.732156900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replicate single channel across three channels to match DenseNet input shape\n",
    "train_images_resized = np.repeat(train_images_resized[..., np.newaxis], 3, axis=-1)\n",
    "test_images_resized = np.repeat(test_images_resized[..., np.newaxis], 3, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:44.051859200Z",
     "start_time": "2024-02-11T21:55:44.039366900Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Transfer learning\n",
    "## Get and modify pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get pre-trained keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:47.714916200Z",
     "start_time": "2024-02-11T21:55:44.049859600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet model without the top layer\n",
    "# base_model = DenseNet121(\n",
    "base_model = DenseNet121(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(32, 32, 3),\n",
    ")\n",
    "# DenseNet stands for “Densely Connected Convolutional Networks,” and it is so named because it connects every layer to every other layer in a feedforward fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Show model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.367792300Z",
     "start_time": "2024-02-11T21:55:47.716916400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get model summary\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Show model blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.378785400Z",
     "start_time": "2024-02-11T21:55:48.929962300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get model blocks\n",
    "[_.name for _ in base_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.381783400Z",
     "start_time": "2024-02-11T21:55:48.935957900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Model has: {len(base_model.layers)} layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add custom classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.414760900Z",
     "start_time": "2024-02-11T21:55:48.940954900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get output tensor of the last layer in the base model\n",
    "output_tensor = base_model.output\n",
    "\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add layer to the end of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.474723900Z",
     "start_time": "2024-02-11T21:55:48.945953400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add global average pooling operation for spatial data\n",
    "output_tensor = GlobalAveragePooling2D()(output_tensor)\n",
    "\n",
    "#  Add a fully connected (dense) layer on top of the previous x tensor\n",
    "output_tensor = Dense(\n",
    "    units=256,\n",
    "    activation='relu'\n",
    ")(output_tensor)\n",
    "# ReLU activation introduces non-linearity by mapping negative values to zero and leaving positive values unchanged.\n",
    "\n",
    "# Add last layer with 10 units, which represents the number of output classes in a classification task\n",
    "predictions = Dense(\n",
    "    units=10,\n",
    "    activation='softmax'\n",
    ")(output_tensor)\n",
    "#Softmax normalizes the output values across the units to represent class probabilities, ensuring that the sum of probabilities across all classes equals 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Combine model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.550676600Z",
     "start_time": "2024-02-11T21:55:48.949948400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the base model with custom layers\n",
    "model = Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=predictions\n",
    ")\n",
    "\n",
    "# Freeze layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.570666Z",
     "start_time": "2024-02-11T21:55:48.953946800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.01\n",
    "    ),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T21:55:49.572664Z",
     "start_time": "2024-02-11T21:55:48.957945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get time log\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Get TensorBoard \n",
    "tboard_callback = TensorBoard(\n",
    "    log_dir = logs,\n",
    "    histogram_freq = 1,\n",
    "    profile_batch = '500,520'\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=2,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=False  # Restore weights from the epoch with the best validation loss\n",
    ")\n",
    "# Define terminate if Nan result appeared\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "# Define progress bar with metrics\n",
    "progbar_logger = ProgbarLogger(\n",
    "    count_mode=\"samples\",\n",
    "    stateful_metrics=['acc'],\n",
    ")\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.01\n",
    "    decay_step = 1\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "# Define a learning rate scheduler callback\n",
    "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:13:00.922615700Z",
     "start_time": "2024-02-11T21:55:48.961943300Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images_resized,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    batch_size=32, # Hyperparameter to reduce tim but loose accuracy\n",
    "    validation_data=(test_images_resized, test_labels),\n",
    "    callbacks = [\n",
    "        early_stopping,\n",
    "        terminate_on_nan,\n",
    "        progbar_logger,\n",
    "        lr_scheduler_callback,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:13:00.936064700Z",
     "start_time": "2024-02-11T22:13:00.924613700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:13:00.982341800Z",
     "start_time": "2024-02-11T22:13:00.932070300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "%tensorboard --logdir=logs --port=6012\n",
    "\n",
    "# !!! Got message like 'Reusing TensorBoard on port XXXX' - change port !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get graph\n",
    "## We can get loss as a trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T22:13:30.912480100Z",
     "start_time": "2024-02-11T22:13:00.964354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot train loss\n",
    "sns.lineplot(\n",
    "    x=range(1, len(history.history['loss']) + 1),\n",
    "    y=history.history['loss'],\n",
    "    label='Train',\n",
    ")\n",
    "\n",
    "# Plot validation loss\n",
    "sns.lineplot(\n",
    "    x=range(1, len(history.history['val_loss']) + 1),\n",
    "    y=history.history['val_loss'],\n",
    "    label='Test',\n",
    ")\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images_resized, test_labels)\n",
    "print(f'Test accuracy: {test_acc: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When the training loss is higher than the test loss in machine learning, it typically indicates that the model is overfitting the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
