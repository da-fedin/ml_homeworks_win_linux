{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc6a390695eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:03.335093100Z",
     "start_time": "2024-02-22T09:36:03.319103400Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "\n",
    "import sacrebleu\n",
    "import itertools\n",
    "\n",
    "from transformers import TFMarianMTModel, MarianTokenizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2d80571cbbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:09.222607100Z",
     "start_time": "2024-02-22T09:36:03.339188100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6e96bbb3483a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:12.274645700Z",
     "start_time": "2024-02-22T09:36:09.216610300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define input text\n",
    "input_text = \"Hello, how have You been?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer([input_text], return_tensors=\"tf\", padding=True)\n",
    "\n",
    "# Translate input text\n",
    "translated_tokens = model.generate(input_ids[\"input_ids\"])\n",
    "\n",
    "# Decode translated tokens\n",
    "translated_text = tokenizer.decode(\n",
    "    translated_tokens.numpy()[0], skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(f\"Input Text: {input_text}.\")\n",
    "print(f\"Translated Text: {translated_text}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941397cb908869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:12.281796100Z",
     "start_time": "2024-02-22T09:36:12.269780500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "references = [input_text]\n",
    "hypotheses = [translated_text]\n",
    "\n",
    "bleu_score = sacrebleu.corpus_bleu(hypotheses, [references]).score\n",
    "\n",
    "chrf_score = sacrebleu.corpus_chrf(hypotheses, [references]).score\n",
    "\n",
    "ter_score = sacrebleu.corpus_ter(hypotheses, [references]).score\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.2f}.\")\n",
    "print(f\"chrF Score: {chrf_score:.2f}.\")\n",
    "print(f\"TER Score: {ter_score:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb8e9204e698e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:12.331626Z",
     "start_time": "2024-02-22T09:36:12.279797500Z"
    }
   },
   "outputs": [],
   "source": [
    "config = model.config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c9973e7e7a85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:36:27.430426100Z",
     "start_time": "2024-02-22T09:36:12.294417800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model name\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Define input text and reference translation\n",
    "input_text = \"Hello, how have you been?\"\n",
    "reference_translation = \"Привіт, як справи?\"\n",
    "\n",
    "# Define candidate configurations to try\n",
    "configurations = [\n",
    "    {\"max_length\": 128, \"num_beams\": 4},\n",
    "    {\"max_length\": 256, \"num_beams\": 8},\n",
    "    {\"max_length\": 512, \"num_beams\": 16},\n",
    "]\n",
    "\n",
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(config)\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        input_ids, max_length=config[\"max_length\"], num_beams=config[\"num_beams\"]\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        translated_tokens.numpy()[0], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [[reference_translation]]).score\n",
    "\n",
    "    # Update best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "        best_configuration = config\n",
    "\n",
    "# Print the best configuration and BLEU score\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(f\"Best BLEU Score: {best_bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5dc40847c54ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:40:15.075466200Z",
     "start_time": "2024-02-22T09:38:40.814011300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define candidate parameter values\n",
    "max_lengths = [128, 256, 512]\n",
    "num_beams_list = [4, 8, 16]\n",
    "num_hidden_layers_list = [2, 4, 6]\n",
    "# max_position_embeddings_list = [\n",
    "#     128,\n",
    "#     256,\n",
    "#     512,\n",
    "# ]  # Define different values for max_position_embeddings\n",
    "# use_cache_list = [True, False]  # Define different values for use_cache\n",
    "\n",
    "# Generate all possible combinations of parameter values\n",
    "configurations = list(\n",
    "    itertools.product(\n",
    "        max_lengths,\n",
    "        num_beams_list,\n",
    "        num_hidden_layers_list,\n",
    "        # max_position_embeddings_list,\n",
    "        # use_cache_list,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "best_configuration = None\n",
    "configuration_amount = 0\n",
    "\n",
    "for config in configurations:\n",
    "    configuration_amount += 1\n",
    "    # max_length, num_beams, num_hidden_layers, max_pos_emb, cache = config\n",
    "    max_length, num_beams, num_hidden_layers = config\n",
    "\n",
    "    current_configuration = config\n",
    "    print(f\"Current configuration: {current_configuration}\")\n",
    "\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(\n",
    "        {\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            # \"max_position_embeddings\": max_pos_emb,\n",
    "            # \"use_cache\": cache,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        input_ids, max_length=max_length, num_beams=num_beams\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        translated_tokens.numpy()[0], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    translation_time = time.time() - start_time\n",
    "    print(f\"translation_time: {translation_time:.2f}.\")\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [[reference_translation]]).score\n",
    "\n",
    "    # Update best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "        best_configuration = {\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            # \"max_position_embeddings\": max_pos_emb,\n",
    "            # \"use_cache\": cache,\n",
    "        }\n",
    "        time_of_best_translation = translation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22122e7c62f0e17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T09:42:42.017022700Z",
     "start_time": "2024-02-22T09:42:42.003937300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the best configuration and BLEU score\n",
    "print(f\"Configuration amount: {configuration_amount}.\")\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(f\"Best BLEU Score: {best_bleu_score:.2f}.\")\n",
    "print(f\"Time: {time_of_best_translation:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
