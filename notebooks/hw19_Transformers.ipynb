{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46340a83256568b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b295127e863a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:17.090128Z",
     "start_time": "2024-02-23T12:45:17.026354700Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import sacrebleu\n",
    "import itertools\n",
    "\n",
    "from transformers import TFMarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444f09364447be8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Configuring logger and wornings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc6a390695eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:17.123165400Z",
     "start_time": "2024-02-23T12:45:17.097555700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\":\")\n",
    "\n",
    "# Configure warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f530337de00323",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting model, observations\n",
    "Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2d80571cbbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:23.524325800Z",
     "start_time": "2024-02-23T12:45:17.104059800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get model pretrained to translate from English to Ukrainian\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "\n",
    "# Get tokenizer\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Instantiate a pretrained TF 2.0 model from a pre-trained model configuration\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Get model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a24d0584f3624b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Translate clause example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6e96bbb3483a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:25.787661Z",
     "start_time": "2024-02-23T12:45:23.530322400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define input text\n",
    "input_text = \"What's your problem?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer(\n",
    "    [input_text],\n",
    "    return_tensors=\"tf\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "# Translate input text\n",
    "translated_tokens = model.generate(\n",
    "    inputs=input_ids[\"input_ids\"],\n",
    ")\n",
    "\n",
    "# Decode translated tokens\n",
    "translated_text = tokenizer.decode(\n",
    "    token_ids=translated_tokens.numpy()[0],\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "logger.info(f\"Runtime: {(time.time() - start_time):.2f} seconds.\")\n",
    "\n",
    "print(f\"Input Text: {input_text}.\")\n",
    "print(f\"Translated Text: {translated_text}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ca0113ac17eb7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The result looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752318d8318923c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941397cb908869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:25.796157100Z",
     "start_time": "2024-02-23T12:45:25.789660100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set input clause as reference for the scoring\n",
    "input = [input_text]\n",
    "\n",
    "# Set output as an object\n",
    "generated_output = [translated_text]\n",
    "\n",
    "# Set human generated clause\n",
    "human_output = [\"У чому твоя проблема?\"]\n",
    "\n",
    "# Evaluate the quality of machine-generated translations by comparing them to one or more human-generated reference translations\n",
    "bleu_score = sacrebleu.corpus_bleu(\n",
    "    hypotheses=generated_output,\n",
    "    references=[human_output],\n",
    ").score\n",
    "\n",
    "# Quantifie the similarity between machine-generated translations and human-generated references\n",
    "chrf_score = sacrebleu.corpus_chrf(\n",
    "    hypotheses=generated_output,\n",
    "    references=[human_output],\n",
    ").score\n",
    "\n",
    "# Measure the edit distance between the machine-generated translation and the reference translation\n",
    "ter_score = sacrebleu.corpus_ter(\n",
    "    hypotheses=generated_output,\n",
    "    references=[human_output],\n",
    ").score\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.2f}.\")\n",
    "print(f\"chrF Score: {chrf_score:.2f}.\")\n",
    "print(f\"TER Score: {ter_score:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647087a379ce5a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Look up model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb8e9204e698e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:25.856899100Z",
     "start_time": "2024-02-23T12:45:25.799273900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get configuration\n",
    "config = model.config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962f0d59f8fe77d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tune pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26904babca8c24e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:25.856899100Z",
     "start_time": "2024-02-23T12:45:25.813834700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the reference result\n",
    "reference_translation = \"Привіт, як справи?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45e17673fa87ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8966581b1a0debf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:45:25.857970900Z",
     "start_time": "2024-02-23T12:45:25.823934100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define config parameter values\n",
    "max_lengths = [128, 256, 512]\n",
    "num_beams_list = [4, 8, 16]\n",
    "num_hidden_layers_list = [2, 4, 6]\n",
    "max_position_embeddings_list = [\n",
    "    64,\n",
    "    128,\n",
    "    256,\n",
    "]\n",
    "\n",
    "# Generate all possible combinations of parameter values\n",
    "configurations = list(\n",
    "    itertools.product(\n",
    "        max_lengths,\n",
    "        num_beams_list,\n",
    "        num_hidden_layers_list,\n",
    "        max_position_embeddings_list,\n",
    "    )\n",
    ")\n",
    "\n",
    "logger.info(f\"Configuration amount: {len(configurations)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f5695bb35a6bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get search among parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5dc40847c54ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:49:34.252461100Z",
     "start_time": "2024-02-23T12:45:37.886022300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "reference_time = None\n",
    "best_configuration = None\n",
    "\n",
    "# Set loops\n",
    "for config in configurations:\n",
    "    max_length, num_beams, num_hidden_layers, max_pos_emb = config\n",
    "\n",
    "    current_configuration = config\n",
    "    print(f\"Current configuration: {current_configuration}.\")\n",
    "\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(\n",
    "        config_dict={\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            \"max_position_embeddings\": max_pos_emb,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(\n",
    "        text=input_text,\n",
    "        return_tensors=\"tf\",\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        inputs=input_ids,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        token_ids=translated_tokens.numpy()[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    translation_time = time.time() - start_time\n",
    "    print(f\"translation time: {translation_time:.2f}.\")\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(\n",
    "        hypotheses=generated_output,\n",
    "        references=[human_output],\n",
    "    ).score\n",
    "\n",
    "    if reference_time is None:\n",
    "        reference_time = translation_time\n",
    "\n",
    "        logger.info(f\"Reference time:{reference_time:.2f}.\")\n",
    "\n",
    "    if translation_time < reference_time:\n",
    "        time_of_fast_translation = translation_time\n",
    "        fast_configuration = current_configuration\n",
    "\n",
    "    # Update the best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "        best_configuration = current_configuration\n",
    "        time_of_best_translation = translation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22122e7c62f0e17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T12:50:12.629624100Z",
     "start_time": "2024-02-23T12:50:12.623017700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the best configuration and BLEU score\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(f\"Best BLEU Score: {best_bleu_score:.2f}.\")\n",
    "print(f\"Time: {time_of_best_translation:.2f} seconds.\\n\")\n",
    "print(\"Fast Configuration:\", fast_configuration)\n",
    "print(f\"Fast time: {time_of_fast_translation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3916225194368d9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Summary\n",
    "1. Pretrained MarianMT model used to translate a clause from English to Ukrainian.\n",
    "2. Reasonable amount of the configuration parameters had been chosen tu tune the pre-trained model in terms of score and time.\n",
    "3.  While the best score search shows reasonable result, the speed search doesn't show logic, which means, that it should be discovered separately. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
