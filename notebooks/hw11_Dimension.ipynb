{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mute annoying warnings in notebook\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "# For runtime estimation\n",
    "# import time\n",
    "\n",
    "# For Data science\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import (\n",
    "    # model_selection,\n",
    "    # ensemble,\n",
    "    # datasets\n",
    "    # tree,\n",
    "    # linear_model,\n",
    "    # neighbors,\n",
    "    preprocessing,\n",
    "    # svm,\n",
    "    # metrics,\n",
    "    decomposition\n",
    ")\n",
    "\n",
    "# For visualization\n",
    "# general\n",
    "import seaborn as sns\n",
    "\n",
    "# Math plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For dealing with missing data\n",
    "# import missingno as msno\n",
    "\n",
    "# For timing\n",
    "# For modules\n",
    "# from sources import (\n",
    "#     check_is_na,\n",
    "    # get_category_encoded,\n",
    "    # get_heatmap,\n",
    "    # get_dataframe_scaled,\n",
    "    # three_sigma_cleared,\n",
    "    # get_kde_comparison,\n",
    "    # get_model_score,\n",
    "# )\n",
    "\n",
    "# Dealing with classification with imbalanced classes\n",
    "# from imblearn import (\n",
    "#     over_sampling,\n",
    "#     # under_sampling,\n",
    "#     # combine,\n",
    "# )\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from file\n",
    "data = pd.read_csv(\n",
    "    \"../data/SouthGermanCredit.asc\",\n",
    "    delimiter=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Processing\n",
    "\n",
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get principal component analyzer\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "# Fit scaled data\n",
    "X_pca = pca.fit(X_scaled)\n",
    "\n",
    "# Get explained variance (amount of variance explained by each of the selected components)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Get cumulative explained variance for retained features\n",
    "cumulative_explained_variance_ratio = np.cumsum(\n",
    "    explained_variance_ratio\n",
    ")\n",
    "\n",
    "# Plot explained variance\n",
    "sns.lineplot(\n",
    "    data=explained_variance_ratio,\n",
    "    label='variance',\n",
    "    color='g',\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('explained_variance_ratio')\n",
    "axis_2 = plt.gca().twinx()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=cumulative_explained_variance_ratio,\n",
    "    label='cumulative variance',\n",
    "    color='r',\n",
    "    marker='s'\n",
    ")\n",
    "\n",
    "plt.title('Explained variance by principal components')\n",
    "plt.ylabel('cumulative_explained_variance_ratio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get amount of retained components with cumulative explained variance more than 70%\n",
    "retained_components = np.argmax(\n",
    "    cumulative_explained_variance_ratio >= .7\n",
    ")\n",
    "\n",
    "retained_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analyzer for only components which cumulative explained variance is more than 70%\n",
    "pca_reduced = decomposition.PCA(n_components=retained_components)\n",
    "\n",
    "# Get decomposition for chosen components\n",
    "X_reduced = pca_reduced.fit_transform(X_scaled)\n",
    "\n",
    "# Get variance loss\n",
    "loss = 1 - cumulative_explained_variance_ratio[retained_components]\n",
    "\n",
    "print(f'Variance loss is {loss:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
