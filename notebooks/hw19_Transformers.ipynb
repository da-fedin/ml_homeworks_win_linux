{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b295127e863a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:41.405919500Z",
     "start_time": "2024-02-22T13:02:41.387798Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import sacrebleu\n",
    "import itertools\n",
    "\n",
    "from transformers import TFMarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc6a390695eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:41.433743600Z",
     "start_time": "2024-02-22T13:02:41.409916700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\":\")\n",
    "\n",
    "# Configure warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2d80571cbbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:47.127486900Z",
     "start_time": "2024-02-22T13:02:41.437739800Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-uk\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = TFMarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6e96bbb3483a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:50.380607Z",
     "start_time": "2024-02-22T13:02:47.130486100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define input text\n",
    "input_text = \"Hello, how have You been?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer([input_text], return_tensors=\"tf\", padding=True)\n",
    "\n",
    "# Translate input text\n",
    "translated_tokens = model.generate(input_ids[\"input_ids\"])\n",
    "\n",
    "# Decode translated tokens\n",
    "translated_text = tokenizer.decode(\n",
    "    translated_tokens.numpy()[0], skip_special_tokens=True\n",
    ")\n",
    "\n",
    "logger.info(f\"Runtime: {(time.time() - start_time):.2f} seconds.\")\n",
    "\n",
    "print(f\"Input Text: {input_text}.\")\n",
    "print(f\"Translated Text: {translated_text}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941397cb908869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:50.390736Z",
     "start_time": "2024-02-22T13:02:50.374519800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "references = [input_text]\n",
    "hypotheses = [translated_text]\n",
    "\n",
    "bleu_score = sacrebleu.corpus_bleu(hypotheses, [references]).score\n",
    "\n",
    "chrf_score = sacrebleu.corpus_chrf(hypotheses, [references]).score\n",
    "\n",
    "ter_score = sacrebleu.corpus_ter(hypotheses, [references]).score\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.2f}.\")\n",
    "print(f\"chrF Score: {chrf_score:.2f}.\")\n",
    "print(f\"TER Score: {ter_score:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb8e9204e698e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:50.448739800Z",
     "start_time": "2024-02-22T13:02:50.386736800Z"
    }
   },
   "outputs": [],
   "source": [
    "config = model.config\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26904babca8c24e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:50.449741900Z",
     "start_time": "2024-02-22T13:02:50.406545400Z"
    }
   },
   "outputs": [],
   "source": [
    "reference_translation = \"Привіт, як справи?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8966581b1a0debf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:50.502863400Z",
     "start_time": "2024-02-22T13:02:50.425964600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define candidate parameter values\n",
    "max_lengths = [128, 256, 512]\n",
    "num_beams_list = [4, 8, 16]\n",
    "num_hidden_layers_list = [2, 4, 6]\n",
    "max_position_embeddings_list = [\n",
    "    64,\n",
    "    128,\n",
    "    256,\n",
    "]\n",
    "# use_cache_list = [True, False]  # Define different values for use_cache\n",
    "\n",
    "# Generate all possible combinations of parameter values\n",
    "configurations = list(\n",
    "    itertools.product(\n",
    "        max_lengths,\n",
    "        num_beams_list,\n",
    "        num_hidden_layers_list,\n",
    "        max_position_embeddings_list,\n",
    "        # use_cache_list,\n",
    "    )\n",
    ")\n",
    "\n",
    "logger.info(f\"Configuration amount: {len(configurations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5dc40847c54ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:09:40.260795900Z",
     "start_time": "2024-02-22T13:04:45.419512200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate each configuration and choose the one with the highest BLEU score\n",
    "best_bleu_score = 0\n",
    "reference_time = None\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    max_length, num_beams, num_hidden_layers, max_pos_emb = config\n",
    "\n",
    "    current_configuration = config\n",
    "    print(f\"Current configuration: {current_configuration}\")\n",
    "\n",
    "    # Set model configuration\n",
    "    model.config = model.config.from_dict(\n",
    "        {\n",
    "            \"max_length\": max_length,\n",
    "            \"num_beams\": num_beams,\n",
    "            \"num_hidden_layers\": num_hidden_layers,\n",
    "            \"max_position_embeddings\": max_pos_emb,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(\n",
    "        text=input_text,\n",
    "        return_tensors=\"tf\",\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Translate input text\n",
    "    translated_tokens = model.generate(\n",
    "        inputs=input_ids,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "\n",
    "    # Decode translated tokens\n",
    "    translated_text = tokenizer.decode(\n",
    "        token_ids=translated_tokens.numpy()[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    translation_time = time.time() - start_time\n",
    "    print(f\"translation time: {translation_time:.2f}.\")\n",
    "\n",
    "    # Compute BLEU score\n",
    "    hypotheses = [translated_text]\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypotheses, [[reference_translation]]).score\n",
    "\n",
    "    if reference_time is None:\n",
    "        reference_time = translation_time\n",
    "        logger.info(f\"Reference time:{reference_time:.2f}.\")\n",
    "\n",
    "    if translation_time < reference_time:\n",
    "        time_of_fast_translation = translation_time\n",
    "\n",
    "        fast_configuration = current_configuration\n",
    "\n",
    "    # Update the best configuration if BLEU score is higher\n",
    "    if bleu_score > best_bleu_score:\n",
    "        best_bleu_score = bleu_score\n",
    "\n",
    "        best_configuration = current_configuration\n",
    "\n",
    "        time_of_best_translation = translation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22122e7c62f0e17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T13:10:08.813698600Z",
     "start_time": "2024-02-22T13:10:08.796556800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the best configuration and BLEU score\n",
    "print(\"Best Configuration:\", best_configuration)\n",
    "print(f\"Best BLEU Score: {best_bleu_score:.2f}.\")\n",
    "print(f\"Time: {time_of_best_translation:.2f} seconds.\\n\")\n",
    "print(\"Fast Configuration:\", fast_configuration)\n",
    "print(f\"Fast time: {time_of_fast_translation:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
