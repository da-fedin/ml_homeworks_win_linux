{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mute annoying warnings in notebook\n",
    "import warnings\n",
    "\n",
    "# For Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "\n",
    "# For graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import (\n",
    "    model_selection,\n",
    "    tree,\n",
    "    linear_model,\n",
    "    metrics,\n",
    ")\n",
    "\n",
    "# For modules\n",
    "from sources import (\n",
    "    check_is_na,\n",
    "    get_category_encoded,\n",
    "    get_heatmap,\n",
    "    get_dataframe_scaled,\n",
    "    three_sigma_cleared,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names\n",
    "column_names = [\n",
    "    \"A1\",\n",
    "    \"A2\",\n",
    "    \"A3\",\n",
    "    \"A4\",\n",
    "    \"A5\",\n",
    "    \"A6\",\n",
    "    \"A7\",\n",
    "    \"A8\",\n",
    "    \"A9\",\n",
    "    \"A10\",\n",
    "    \"A11\",\n",
    "    \"A12\",\n",
    "    \"A13\",\n",
    "    \"A14\",\n",
    "    \"A15\",\n",
    "    \"Target\",\n",
    "]\n",
    "\n",
    "# Get dataset from file\n",
    "data = pd.read_csv(\"../data/crx.data\", delimiter=\",\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get columns by data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframes for columns by data type\n",
    "categorical_columns = data.select_dtypes(include=[\"object\"])\n",
    "float_columns = data.select_dtypes(include=[\"float64\"])\n",
    "integer_columns = data.select_dtypes(include=[\"int64\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Replace ? symbols to Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ? to np.Nan\n",
    "categorical_columns.replace(to_replace=\"?\", value=np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Concatenate subsets to clear them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subsets\n",
    "frames = [float_columns, categorical_columns]\n",
    "\n",
    "# Concatenate subsets horizontally\n",
    "df = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Drop rows with Nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows\n",
    "dropped_df = df.dropna(axis=\"rows\")\n",
    "\n",
    "# Check for Nans\n",
    "check_is_na(dropped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change A2 type from object to numeric\n",
    "dropped_df[\"A2\"] = pd.to_numeric(dropped_df[\"A2\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get diagram with missing values\n",
    "msno.matrix(dropped_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are really no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Scale continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale dataset\n",
    "# scaled_df = get_dataframe_scaled(\n",
    "#     dataset=dropped_df,\n",
    "#     omit_feature_names=['Target', 'A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13', 'A14']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value distribution for continuous data\n",
    "sns.boxplot([dropped_df.A2, dropped_df.A3, dropped_df.A8]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At least feature 'A8' has out-layers. Let's clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values with deviation more than 3 sigma\n",
    "cleared_df = three_sigma_cleared(\n",
    "    dataset=dropped_df, feature_names=[\"A2\", \"A3\", \"A8\"], sigmas=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot([cleared_df.A2, cleared_df.A3, cleared_df.A8]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, there are no values out 3-sigma threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encode categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical feature name list from dataset\n",
    "columns_to_encode = categorical_columns.columns[:-1]\n",
    "\n",
    "# Encode categorical features\n",
    "encoded_df = get_category_encoded(\n",
    "    dataset=cleared_df,\n",
    "    category_names=columns_to_encode,\n",
    "    encoder_type=\"LabelEncoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get Tree classification\n",
    "Split dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature and target subsets\n",
    "X = encoded_df.drop(\"Target\", axis=1)\n",
    "y = encoded_df[\"Target\"]\n",
    "\n",
    "# Get split subsets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.3, random_state=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tree classifier\n",
    "tree_classifier = tree.DecisionTreeClassifier(\n",
    "    random_state=42, max_depth=6, criterion=\"gini\"\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Gini Importance as a metrics\n",
    "importance_array = tree_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here: Gini Importance (Mean Decrease in Impurity) calculates each feature importance as the sum over the number of splits (across all tress) that include the feature, proportionally to the number of samples it splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from array\n",
    "importance_df = pd.DataFrame(\n",
    "    data=importance_array,\n",
    "    columns=[\"importance\"],\n",
    ")\n",
    "\n",
    "# Make column of indexes\n",
    "importance_df[\"feature\"] = [x for x in range(0, len(importance_df.values))]\n",
    "\n",
    "# Visualize importance\n",
    "sns.barplot(data=importance_df, x=\"feature\", y=\"importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is a obviously main feature in dataset. Let's find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximal importance\n",
    "max_importance = importance_df.importance.max()\n",
    "\n",
    "# Get index of maximal importance\n",
    "important_feature_index = importance_df[\n",
    "    importance_df[\"importance\"] == max_importance\n",
    "].index.values[0]\n",
    "\n",
    "# Find feature name by index\n",
    "main_feature = encoded_df.columns[important_feature_index]\n",
    "\n",
    "print(f\"Maximum of importance {max_importance:.2f} has feature: {main_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show tree\n",
    "tree.plot_tree(tree_classifier);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The tree looks amazing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_predicted_tree = tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from test and predicted values\n",
    "data_to_compare = pd.DataFrame(\n",
    "    {\"values from test\": y_test, \"predicted values\": y_predicted_tree}\n",
    ")\n",
    "\n",
    "# Visualize amount of predicted values\n",
    "sns.barplot(\n",
    "    x=\"value\",\n",
    "    y=\"index\",\n",
    "    hue=\"variable\",\n",
    "    data=pd.melt(data_to_compare.reset_index(), id_vars=\"index\"),\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of observations in test dataset and and predicted dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Prediction looks good. Let's make metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "y_pred = tree_classifier.predict(X_train)\n",
    "\n",
    "# Get accuracy\n",
    "tree_accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "\n",
    "print(f\"Accuracy of tree is: {tree_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Regularisation by encoding and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "encoded_df = get_category_encoded(\n",
    "    dataset=encoded_df,\n",
    "    category_names=[\"Target\"],\n",
    "    encoder_type=\"LabelEncoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaled_df = get_dataframe_scaled(dataset=encoded_df, omit_feature_names=[\"Target\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new heatmap\n",
    "get_heatmap(scaled_df, \"encoded_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are correlating features A5 and A4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Deal with correlating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new combination for weight features\n",
    "encoded_df[\"A4+A5\"] = encoded_df[\"A4\"] + encoded_df[\"A5\"]\n",
    "\n",
    "# Drop combination components\n",
    "encoded_df.drop(\n",
    "    columns=[\n",
    "        \"A4\",\n",
    "        \"A5\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Get new heatmap\n",
    "get_heatmap(encoded_df, \"encoded_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature and target subsets\n",
    "X = encoded_df.drop(\"Target\", axis=1)\n",
    "y = encoded_df[\"Target\"]\n",
    "\n",
    "# Get split subsets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.3, random_state=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get regression object\n",
    "regression_model = linear_model.LogisticRegression()\n",
    "\n",
    "# Get fit\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "coefficients = regression_model.coef_.T\n",
    "\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from array\n",
    "coefficient_df = pd.DataFrame(\n",
    "    data=coefficients,\n",
    "    columns=[\"coefficients\"],\n",
    ")\n",
    "\n",
    "# Make column of indexes\n",
    "coefficient_df[\"feature\"] = [x for x in range(0, len(coefficient_df.values))]\n",
    "\n",
    "# Visualize importance\n",
    "sns.barplot(data=coefficient_df, x=\"feature\", y=\"coefficients\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks like there is a main features. Let's find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximal importance\n",
    "max_index = coefficient_df.coefficients.min()\n",
    "\n",
    "# Get index of maximal importance\n",
    "important_feature_index = coefficient_df[\n",
    "    coefficient_df[\"coefficients\"] == max_index\n",
    "].index\n",
    "\n",
    "# Find feature name by index\n",
    "main_feature = list(encoded_df.columns[important_feature_index])[0]\n",
    "\n",
    "print(f\"Maximum coefficient value {max_importance:.2f} has feature: {main_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_predicted_regression = regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get density plot\n",
    "# for test data\n",
    "sns.kdeplot(\n",
    "    y_test,\n",
    "    fill=False,\n",
    "    color=\"r\",\n",
    "    label=\"test subset\",\n",
    ")\n",
    "\n",
    "# for predicted data\n",
    "sns.kdeplot(\n",
    "    y_predicted_regression,\n",
    "    fill=True,\n",
    "    color=\"b\",\n",
    "    label=\"predicted\",\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.title(\"Distribution of observations in test dataset and and predicted dataset\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "y_predicted_regression = regression_model.predict(X_train)\n",
    "\n",
    "# Get accuracy\n",
    "regression_accuracy = metrics.accuracy_score(y_train, y_predicted_regression)\n",
    "\n",
    "print(f\"Accuracy of regression is: {regression_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
