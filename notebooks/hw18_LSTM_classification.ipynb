{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148950651412c229",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1ede2c2c2ef21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:36.104692400Z",
     "start_time": "2024-02-17T17:45:36.063703500Z"
    }
   },
   "outputs": [],
   "source": [
    "# To mute annoying warnings in notebook\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# For data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ed05b4a8634ed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0c1971244b6b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:37.280323500Z",
     "start_time": "2024-02-17T17:45:36.110688900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset from file\n",
    "df = pd.read_csv(\n",
    "    f\"../data/IMDB_Dataset.csv\",\n",
    ")\n",
    "\n",
    "# Show dataset head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21c0bcc36c60a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:53.955200700Z",
     "start_time": "2024-02-17T17:45:37.278327100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000)  # Set maximum number of words to keep\n",
    "tokenizer.fit_on_texts(df['review'])  # Fit tokenizer on the reviews\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])  # Convert text to sequences of word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:53.956200Z",
     "start_time": "2024-02-17T17:45:53.951197300Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 20000  # Only consider the top 20k words\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6195b158bb6e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:54.597750800Z",
     "start_time": "2024-02-17T17:45:53.957199Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(\n",
    "    sequences=sequences,\n",
    "    maxlen=max_length,\n",
    "    padding='post',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86659c5ba1998808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:54.632562300Z",
     "start_time": "2024-02-17T17:45:54.600749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get split subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences,\n",
    "    df['sentiment'],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bedcae7fb78751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T17:45:55.848949Z",
     "start_time": "2024-02-17T17:45:54.633563900Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(\n",
    "    shape=(None,),\n",
    "    dtype=\"int32\",\n",
    ")\n",
    "\n",
    "x = layers.Embedding(\n",
    "    input_dim=max_features,\n",
    "    output_dim=128\n",
    ")(inputs)\n",
    "\n",
    "x = layers.Bidirectional(\n",
    "    layers.LSTM(\n",
    "        units=64,\n",
    "        return_sequences=True,\n",
    "    )\n",
    ")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "outputs = layers.Dense(\n",
    "    units=1,\n",
    "    activation=\"sigmoid\",\n",
    ")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53066145fd61b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "\n",
    "print(f\"--- {((time.time() - start_time)):.2f} seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
