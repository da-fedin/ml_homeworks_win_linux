{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fd666fff5ab06174",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# For Data science\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "\n",
    "from sklearn import (\n",
    "    metrics,\n",
    "    linear_model,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# For graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For sources\n",
    "from sources import three_sigma_cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba11971040616eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Getting data, observations\n",
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d039075d99938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from file\n",
    "df = pd.read_csv(\n",
    "    f\"../data/IMDB_Dataset.csv\",\n",
    ")\n",
    "\n",
    "# Show dataset head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024a5c8a83bb8f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check if categories balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930910b051bd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.columns[-1]\n",
    "\n",
    "grouped = df.groupby(review).size()\n",
    "grouped.plot(\n",
    "    kind='bar',\n",
    "    xlabel='Review',\n",
    "    ylabel='Count',\n",
    "    title='Count of Reviews',\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154d1878883edc6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dataframe is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d92c3afcb9434c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check review clause length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13473865e48fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature and target subsets\n",
    "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot the distribution of word counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Distribution of Word Counts\")\n",
    "sns.histplot(x=\"word_count\", data=df, kde=True)\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee24d232318d39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The length of reviews hase the wide range but most of them are less than 500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afc075e97b00c",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be6bdfe66f88f817",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remove out-layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c883464b9ef3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = three_sigma_cleared(\n",
    "    dataset=df,\n",
    "    feature_names=['word_count'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053be2017c323f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot word count by sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5944994c68a6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='sentiment', y='word_count')\n",
    "plt.title('Box Plot of Sentiment vs Word Count')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Word Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad0ca9d636b2a38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Average length of positive and negative reviews are the same. The length is not a classification feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984d9813037a34c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lasy use of spaCy\n",
    "Use only for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f91a5473d34368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained English model\n",
    "nlp = spacy.load(\n",
    "    name=\"en_core_web_sm\",\n",
    "    # disable=[\n",
    "    #     \"tagger\",\n",
    "    #     \"attribute_ruler\",\n",
    "    #     \"lemmatizer\"\n",
    "    # ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc555ff74a523f24",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set word vector length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dab1638f4d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.reset_vectors(width=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e8333389168ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get lemmas from words in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfc09fe6979fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set function to process text\n",
    "def spacy_preprocessed_text(text_to_process: str):\n",
    "    doc = nlp(text_to_process)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = df[:1000] # :TODO: drop this line\n",
    "\n",
    "# Apply the preprocess function to reviews\n",
    "df['processed_review'] = df['review'].apply(spacy_preprocessed_text)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ac92cca7ada09",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Encode sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca829661bc2aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73aca8d9382aab5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Split dataframe to test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d111493f92dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0190b957eb49e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vectorize reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91d980b0c690e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorize data\n",
    "X_train = vectorizer.fit_transform(train_df['processed_review'])\n",
    "X_test = vectorizer.transform(test_df['processed_review'])\n",
    "y_train = train_df['sentiment']\n",
    "y_test = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb43742980f8d85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453eced40adcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Get classifier\n",
    "classifier = linear_model.LogisticRegression(\n",
    "    max_iter=500,\n",
    ")\n",
    "\n",
    "# Fit classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(f\"--- {((time.time() - start_time)):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba3e16a53a1e22",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb1491454137cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabc633927dec7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221fd7c8f359283",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ce8d92f29eb78",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd753b0bd4d78b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=prediction,\n",
    "    labels=classifier.classes_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75ca8527b2f43d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Visualize confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156e256e2ccb711",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix,\n",
    "    display_labels=classifier.classes_,\n",
    ")\n",
    "\n",
    "disp.plot(cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3308b865dd5931",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The amount of fail answers is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc8329d1dcece7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Visualize observations in test dataset and and predicted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2d0047e4079dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get density plot\n",
    "# for test data\n",
    "sns.kdeplot(\n",
    "    y_test,\n",
    "    fill=False,\n",
    "    color='r',\n",
    "    label='test subset',\n",
    ")\n",
    "\n",
    "# for predicted data\n",
    "sns.kdeplot(\n",
    "    prediction,\n",
    "    fill=True,\n",
    "    color='b',\n",
    "    label='predicted',\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.title('Distribution of observations in test dataset and and predicted dataset')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badbcbc2e85b5fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16bd184e17d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=prediction,\n",
    "    target_names=['class 1', 'class 2'],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c75e3a1a3b3e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use spaCy for classification\n",
    "Get dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194c74a3771591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from file\n",
    "df = pd.read_csv(\n",
    "    '../data/IMDB_Dataset.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d4502047d8b75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create blank nlp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9818c5b49b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank nlp object for a given language code.\n",
    "nlp = spacy.blank(name=\"en\")\n",
    "\n",
    "# Show pipe names\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b621d199eb8bbda",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add 'textcat' pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b4b94a98a19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'textcat' pipe if non-present in model\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\n",
    "        'textcat',\n",
    "        last=True\n",
    "    )\n",
    "\n",
    "# Show pipe names\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a26c37f44da4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add labels to pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12b9d5100de0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline component by name\n",
    "textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "# Set list of categories from dataframe target column\n",
    "categories = [_ for _ in df['sentiment'].unique()]\n",
    "\n",
    "# Set labels for pipeline\n",
    "[textcat.add_label(category) for category in categories]\n",
    "\n",
    "textcat.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea8b7ee3c93871",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train model\n",
    "Split dataframe to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd3947fb4cf0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184fcaa581e7600",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get texts and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b336583e75a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_data['review']#.values\n",
    "train_labels = train_data['sentiment']#.values\n",
    "\n",
    "test_texts = test_data['review']#.values\n",
    "test_labels = test_data['sentiment']#.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a025b3c1e1c3a2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf01df9539802c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 8\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f1c55c125379a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698b0bef720088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set responsible for updating weights training\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "# Set control to step size for model parameters updating\n",
    "optimizer.learn_rate = learn_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b043139898c5ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get information for each training instance for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef14e5683300527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set information as list\n",
    "train_examples = []\n",
    "\n",
    "# Get train examples and store them in list\n",
    "for text, label in zip(train_texts, train_labels):\n",
    "    example = Example.from_dict(\n",
    "        predicted=nlp.make_doc(text),\n",
    "        example_dict={\n",
    "            'cats': {label: 1.0}\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    train_examples.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042d01dc344c47b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train model using batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f738b09b062e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the model...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run training\n",
    "for epoch in range(n_epochs):\n",
    "    random.shuffle(train_examples)\n",
    "    losses = {}\n",
    "    batches = minibatch(\n",
    "        items=train_examples,\n",
    "        size=batch_size\n",
    "    )\n",
    "    \n",
    "    for batch in batches:\n",
    "        nlp.update(\n",
    "            examples=batch,\n",
    "            sgd=optimizer,\n",
    "            losses=losses,\n",
    "        )\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} - Loss: {losses['textcat']:.2f}\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a62b3035d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d28c6e95cc8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for text, true_label in zip(test_texts, test_labels):\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)\n",
    "    if predicted_label == true_label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
